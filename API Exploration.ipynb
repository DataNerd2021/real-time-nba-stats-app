{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import teamdetails, commonteamyears, teamgamelogs, playergamelogs, commonplayerinfo, boxscoreadvancedv3, boxscoretraditionalv3, boxscoremiscv3, scoreboardv2\n",
    "from nba_api.live.nba.endpoints import playbyplay\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandavro as pdx\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "from warnings import filterwarnings\n",
    "import json\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Team IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'all_teams.parquet' not in os.listdir('Static Files'):\n",
    "    teams = commonteamyears.CommonTeamYears()\n",
    "    print('Established connection')\n",
    "    teams = teams.get_dict()\n",
    "    print('Retrieved list of dicts')\n",
    "    team_ids = []\n",
    "    for team in tqdm(teams['resultSets'][0]['rowSet']):\n",
    "        team_id = team[1]\n",
    "        team_name = team[2]\n",
    "        start_year = team[3]\n",
    "        end_year = team[4]\n",
    "        team_ids.append((team_id, team_name, start_year, end_year))\n",
    "        time.sleep(0.5)\n",
    "    print('Established list of tuples')\n",
    "    teams = pd.DataFrame(team_ids, columns=['team_id', 'year_founded', 'year_depreciated', 'abbreviation'])\n",
    "    print('Created DataFrame')\n",
    "    teams.to_parquet('Static Files/all_teams.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Team Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'team_details.parquet' not in os.listdir('Static Files'):\n",
    "    teams = pd.read_parquet('Static Files/all_teams.parquet')\n",
    "    initial_df = []\n",
    "    for team in tqdm(teams['team_id']):\n",
    "        get_coaches = teamdetails.TeamDetails(team_id=team, timeout=60)\n",
    "        next_df = get_coaches.get_data_frames()[0]\n",
    "        initial_df.append(next_df)\n",
    "        time.sleep(0.5)\n",
    "    output_df = pd.concat(initial_df)\n",
    "    output_df.to_parquet('Static Files/team_details.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Team Game Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'team_game_logs.parquet' not in os.listdir('Static Files'):\n",
    "    start = 0\n",
    "    end = 1\n",
    "    initial_df = []\n",
    "    for integer in tqdm(range(1,25)):\n",
    "        if end < 10:\n",
    "            get_game_stats = teamgamelogs.TeamGameLogs(season_nullable=f'200{start}-0{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "            start += 1\n",
    "            end += 1\n",
    "        else:\n",
    "            start += 1\n",
    "            end += 1\n",
    "            get_game_stats = teamgamelogs.TeamGameLogs(season_nullable=f'20{start}-{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    output_df = pd.concat(initial_df)\n",
    "    output_df.to_parquet('Static Files/team_game_logs.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Current Player Injury Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'player_injury_reports.avro' not in os.listdir('Static Files'):\n",
    "    player_injuries = pd.concat(pd.read_html('https://www.espn.com/nba/injuries')).fillna('No Info Available')\n",
    "    player_injuries['date_updated'] = datetime.today()\n",
    "    pdx.to_avro('Static Files/player_injury_reports.avro', player_injuries)\n",
    "elif ('player_injury_reports.avro' in os.listdir('Static Files')):\n",
    "    player_injuries = pdx.read_avro('Static Files/player_injury_reports.avro')\n",
    "    if player_injuries['date_updated'].all() != datetime.today():\n",
    "        player_injuries = pd.concat(pd.read_html('https://www.espn.com/nba/injuries')).fillna('No Info Available')\n",
    "        player_injuries['date_updated'] = datetime.today()\n",
    "        pdx.to_avro('Static Files/player_injury_reports.avro', player_injuries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Player Game Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'player_game_logs.parquet' not in os.listdir('Static Files'):\n",
    "    start = 0\n",
    "    end = 1\n",
    "    initial_df = []\n",
    "    for integer in tqdm(range(1,25)):\n",
    "        if end < 10:\n",
    "            get_game_stats = playergamelogs.PlayerGameLogs(season_nullable=f'200{start}-0{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "            start += 1\n",
    "            end += 1\n",
    "        else:\n",
    "            start += 1\n",
    "            end += 1\n",
    "            get_game_stats = playergamelogs.PlayerGameLogs(season_nullable=f'20{start}-{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    output_df = pd.concat(initial_df)\n",
    "    output_df.to_parquet('Static Files/player_game_logs.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Player Statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_parquet('Static Files/player_game_logs.parquet')[['PLAYER_ID']].drop_duplicates()\n",
    "statuses = pdx.read_avro('Static Files/player_statuses.avro')\n",
    "\n",
    "df3 = players.merge(statuses, left_on='PLAYER_ID', right_on='PERSON_ID', how='left', indicator=True)\n",
    "df = df3.loc[df3['_merge'] == 'left_only', 'PLAYER_ID']\n",
    "d = players[players['PLAYER_ID'].isin(df)]\n",
    "d = statuses.merge(d, left_on='PERSON_ID', right_on='PLAYER_ID', how='right')\n",
    "if 'player_statuses.avro' not in os.listdir('Static Files'):\n",
    "    for player in tqdm(players):\n",
    "        player_status = commonplayerinfo.CommonPlayerInfo(player_id=player).get_data_frames()[0][['PERSON_ID', 'ROSTERSTATUS']]\n",
    "        pdx.to_avro('Static Files/player_statuses.avro', player_status, append=True)\n",
    "        time.sleep(0.5)\n",
    "elif ('player_statuses.avro' in os.listdir('Static Files')) & len(d[['PLAYER_ID']].drop_duplicates()['PLAYER_ID']) > 0:\n",
    "    statuses = pdx.read_avro('Static Files/player_statuses.avro')\n",
    "\n",
    "    # carrying out anti join using merge method\n",
    "    df3 = players.merge(statuses, left_on='PLAYER_ID', right_on='PERSON_ID', how='left', indicator=True)\n",
    "    df = df3.loc[df3['_merge'] == 'left_only', 'PLAYER_ID']\n",
    "    d = players[players['PLAYER_ID'].isin(df)]\n",
    "    d = statuses.merge(d, left_on='PERSON_ID', right_on='PLAYER_ID', how='right')\n",
    "    for player in tqdm(d[['PLAYER_ID']].drop_duplicates()['PLAYER_ID']):\n",
    "        player_status = commonplayerinfo.CommonPlayerInfo(player_id=player).get_data_frames()[0][['PERSON_ID', 'ROSTERSTATUS']]\n",
    "        pdx.to_avro('Static Files/player_statuses.avro', player_status, append=True)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Current Player Game Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'current_player_game_logs.parquet' not in os.listdir('Static Files'):\n",
    "    player_game_logs = pd.read_parquet('Static Files/player_game_logs.parquet')\n",
    "    current_player_game_logs = player_game_logs.merge(statuses, left_on='PLAYER_ID', right_on='PERSON_ID').query('ROSTERSTATUS == \"Active\"').to_parquet('Static Files/current_player_game_logs.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Out Live Play-By-Play End Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game ID for the live game you are tracking (replace with actual game ID)\n",
    "game_id = \"0022301196\"\n",
    "\n",
    "# DataFrame to store all player stats during the game\n",
    "player_stats_df = pd.DataFrame()\n",
    "\n",
    "# Track the last processed play to avoid duplicates\n",
    "last_processed_play = None\n",
    "pbp_data = playbyplay.PlayByPlay(game_id).get_dict()\n",
    "plays = pbp_data['game']['actions']\n",
    "\n",
    "# Sort plays by actionNumber to process them in order\n",
    "plays.sort(key=lambda x: x['actionNumber'])\n",
    "\n",
    "# Print the total number of plays\n",
    "print(f\"Total number of plays: {len(plays)}\")\n",
    "\n",
    "for play in tqdm(plays, desc=\"Processing plays\"):\n",
    "    action_number = play['actionNumber']\n",
    "    player_id = play.get('personId', None)\n",
    "    action_type = play.get('actionType', '')\n",
    "    clock = play.get('clock', '')\n",
    "    description = play.get(\"description\", \"\")\n",
    "    descriptor = play.get(\"descriptor\", \"\")\n",
    "    period = play.get(\"period\", \"\")\n",
    "    periodType = play.get(\"periodType\", \"\")\n",
    "    qualifiers = play.get(\"qualifiers\", \"\")\n",
    "    shotDistance = play.get(\"shotDistance\", \"\")\n",
    "    shotResult = play.get(\"shotResult\", \"\")\n",
    "    side = play.get(\"side\", \"\")\n",
    "\n",
    "    # Only process the play if it's new (not processed yet)\n",
    "    if last_processed_play is None or action_number > last_processed_play:\n",
    "\n",
    "        try:\n",
    "            # Fetch traditional stats\n",
    "            traditional_boxscore = boxscoretraditionalv3.BoxScoreTraditionalV3(game_id=game_id)\n",
    "            traditional_stats = traditional_boxscore.get_data_frames()[0]\n",
    "\n",
    "            # Fetch advanced stats\n",
    "            advanced_boxscore = boxscoreadvancedv3.BoxScoreAdvancedV3(game_id=game_id)\n",
    "            advanced_stats = advanced_boxscore.get_data_frames()[0]\n",
    "\n",
    "            # Fetch miscellaneous stats\n",
    "            misc_boxscore = boxscoremiscv3.BoxScoreMiscV3(game_id=game_id)\n",
    "            misc_stats = misc_boxscore.get_data_frames()[0]\n",
    "\n",
    "            # Find the stats for the player involved in the play\n",
    "            traditional_player_stats = traditional_stats[traditional_stats['personId'] == player_id]\n",
    "            advanced_player_stats = advanced_stats[advanced_stats['personId'] == player_id]\n",
    "            misc_player_stats = misc_stats[misc_stats['personId'] == player_id]\n",
    "\n",
    "            if not traditional_player_stats.empty and not advanced_player_stats.empty and not misc_player_stats.empty:\n",
    "                # Extract all columns from traditional stats\n",
    "                traditional_columns = traditional_player_stats.columns.tolist()\n",
    "                traditional_values = traditional_player_stats.iloc[0].tolist()\n",
    "\n",
    "                # Extract all columns from advanced stats\n",
    "                advanced_columns = advanced_player_stats.columns.tolist()\n",
    "                advanced_values = advanced_player_stats.iloc[0].tolist()\n",
    "\n",
    "                # Extract all columns from miscellaneous stats\n",
    "                misc_columns = misc_player_stats.columns.tolist()\n",
    "                misc_values = misc_player_stats.iloc[0].tolist()\n",
    "\n",
    "                # Combine all stats into one dictionary\n",
    "                player_data = {\n",
    "                    'player_id': player_id,\n",
    "                    'action_type': action_type,\n",
    "                    'game_id': game_id,\n",
    "                    'clock': clock,\n",
    "                    'description': description,\n",
    "                    'descriptor': descriptor,\n",
    "                    'period': period,\n",
    "                    'period_type': periodType,\n",
    "                    'qualifiers': qualifiers,\n",
    "                    'shot_distance': shotDistance,\n",
    "                    'shot_result': shotResult,\n",
    "                    'side': side\n",
    "                }\n",
    "\n",
    "                # Add traditional stats to player_data\n",
    "                player_data.update(dict(zip(traditional_columns, traditional_values)))\n",
    "\n",
    "                # Add advanced stats to player_data\n",
    "                player_data.update(dict(zip(advanced_columns, advanced_values)))\n",
    "\n",
    "                # Add miscellaneous stats to player_data\n",
    "                player_data.update(dict(zip(misc_columns, misc_values)))\n",
    "\n",
    "                # Append the new data to the DataFrame\n",
    "                player_stats_df = pd.concat([player_stats_df, pd.DataFrame([player_data])], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Error processing play {action_number}: {e}\")\n",
    "\n",
    "        # Update the last processed play\n",
    "        last_processed_play = action_number\n",
    "\n",
    "        # Sleep before fetching the next batch of plays (adjust this time to API rate limit)\n",
    "        time.sleep(0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    player_stats_df['team_name'] = player_stats_df['teamCity'] + \" \" + player_stats_df['teamName']\n",
    "    player_stats_df.drop(columns=['gameId', 'teamTricode', 'teamSlug', 'personId', 'firstName', 'familyName', 'playerSlug', 'estimatedOffensiveRating', 'estimatedDefensiveRating', 'estimatedNetRating', 'offensiveReboundPercentage', 'defensiveReboundPercentage', 'turnoverRatio', 'estimatedUsagePercentage', 'estimatedPace', 'jerseyNum', 'teamCity', 'teamName'], inplace=True)\n",
    "except KeyError:\n",
    "    player_stats_df.rename(columns={'teamId':'team_id', 'nameI':'player_name', 'fieldGoalsMade':'fg_made', 'fieldGoalsAttempted':'fg_attempts', 'fieldGoalPercentage':'fg_percentage','threePointersMade':'fg3_made', 'threePointersAttempted':'fg3_attempts', 'threePointersPercentage':'fg3_percentage', 'freeThrowsMade':'ft_made', 'freeThrowsAttempted':'ft_attempts', 'freeThrowPercentage':'ft_percentage', 'reboundsOffensive':'offensive_rebounds', 'reboundsDefensive':'defensive_rebounds', 'reboundsTotal':'total_rebounds', 'foulsPersonal':'personal_fouls', 'plusMinusPoints':'plus_minus', 'offensiveRating':'offensive_rating', 'defensiveRating':'defensive_rating', 'netRating':'net_rating', 'assistPercentage':'assist_percentage', 'assistToTurnover':'assist_turnover_ratio', 'assistRatio':'assist_ratio', 'reboundPercentage':'rebound_percentage', 'effectiveFieldGoalPercentage':'eff_fg_percentage', 'trueShootingPercentage':'true_shooting_percentage', 'usagePercentage':'usage_percentage', 'pointsOffTurnovers':'turnover_points', 'pointsSecondChance':'second_chance_points', 'pointsFastBreak':'fast_break_points', 'pointsPaint':'paint_points', 'blocksAgainst':'blocks_against', 'foulsDrawn':'fouls_drawn'}, inplace=True)\n",
    "\n",
    "    player_stats_df['clock'] = player_stats_df['clock'].replace('PT', '').replace('M', '').replace('.00S', '')\n",
    "    pd.set_option(\"display.max_columns\", 0)\n",
    "    best_players = player_stats_df.groupby('team_name')['PIE'].idxmax()\n",
    "    best_players = player_stats_df.loc[best_players, ['player_name', 'team_name', 'PIE']]\n",
    "    team_1 = best_players['team_name'].iloc[0]\n",
    "    player_1 = best_players['player_name'].iloc[0]\n",
    "    player_1_pie = best_players['PIE'].iloc[0]\n",
    "    team_2 = best_players['team_name'].iloc[1]\n",
    "    player_2 = best_players['player_name'].iloc[1]\n",
    "    player_2_pie = best_players['PIE'].iloc[1]\n",
    "    display(player_stats_df.head())\n",
    "    print(f'{team_1}: {player_1} ({player_1_pie}) | {team_2}: {player_2} ({player_2_pie})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.strptime(\"2024-10-04\", \"%Y-%m-%d\")\n",
    "end = datetime.strptime(\"2025-04-15\", \"%Y-%m-%d\")\n",
    "\n",
    "date_range = pd.date_range(start=start, end=end).to_list()\n",
    "\n",
    "games = {}\n",
    "# Assuming 'range' contains the list of dates for the 2024-25 season\n",
    "for date in tqdm(date_range):\n",
    "    json_string = json.loads(scoreboardv2.ScoreboardV2(game_date=date).get_json())\n",
    "\n",
    "    i = 0  # resultSets index for 'GameHeader'\n",
    "    headers = json_string['resultSets'][i].get('headers', '')\n",
    "\n",
    "    # Iterate through each game in the 'rowSet'\n",
    "    for game in json_string['resultSets'][i]['rowSet']:\n",
    "        game_id = game[2]  # Index 2 is the 'GAME_ID'\n",
    "\n",
    "        # Add game_id to the list of games for the specific date\n",
    "        if date in games:\n",
    "            games[date].append(game_id)\n",
    "        else:\n",
    "            games[date] = [game_id]\n",
    "\n",
    "    time.sleep(0.5)  # Delay to avoid rate limits\n",
    "games = {key.strftime('%Y-%m-%d'): value for key, value in games.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '2024-25_game_ids.parquet' not in os.listdir('Static Files')\n",
    "    games_2025 = pd.DataFrame(list(games.items()), columns=['game_date', 'game_id'])\n",
    "    games_2025 = games_2025.explode(column='game_id')\n",
    "    games_2025.to_parquet('Static Files/2024-25_game_ids.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_log_df = pd.read_parquet('Static Files/current_player_game_logs.parquet')\n",
    "game_log_df2 = pd.read_parquet('Static Files/team_game_logs.parquet')\n",
    "\n",
    "def simulation(game_id):\n",
    "    print(f\"Starting mock live updates for game: {game_id}\")\n",
    "    play_by_play = playbyplay.PlayByPlay(game_id)\n",
    "    plays = play_by_play.get_dict()['game']['actions']\n",
    "    df = pd.DataFrame(columns=['game_id','period','period_time_remaining','description','home_score','away_score'])\n",
    "    plays_df = []\n",
    "    for _ in range(len(plays)):\n",
    "        if plays:\n",
    "            latest_play = plays[_]\n",
    "            try:\n",
    "                period = latest_play['period']\n",
    "                period_time_remaining = latest_play['clock'].replace('PT', '').replace('M', ':')[:5]\n",
    "                description = latest_play['description']\n",
    "                home_score = latest_play['scoreHome']\n",
    "                away_score = latest_play['scoreAway']\n",
    "                df2 = pd.DataFrame({'game_id':game_id, 'period':period, 'period_time_remaining':period_time_remaining, 'description':description, 'home_score':home_score, 'away_score':away_score}, index=[0])\n",
    "                plays_df.append(df2)\n",
    "                # print(f\"Q{period} {game_clock}: {description} | Score: {home_score} - {away_score}\")\n",
    "            except KeyError:\n",
    "                pass\n",
    "        else:\n",
    "            print(\"no plays yet...\")\n",
    "    output = pd.concat(plays_df, ignore_index=True)\n",
    "    return output\n",
    "current_game = simulation('0022000196')\n",
    "current_game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Advanced Player Game Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'current_player_advanced_game_stats.parquet' not in os.listdir('Static Files'):\n",
    "\n",
    "    # Filter games for the 2023-24 season\n",
    "    games = game_log_df[game_log_df['SEASON_YEAR'] == '2023-24']['GAME_ID'].unique()\n",
    "\n",
    "    # Iterate over each game\n",
    "    for game_id in tqdm(games):\n",
    "        # Fetch box score data for the current game\n",
    "        game = boxscoreadvancedv3.BoxScoreAdvancedV3(game_id).get_data_frames()[0]\n",
    "\n",
    "        # Iterate over each player in the game\n",
    "        for idx, player_stats in game.iterrows():\n",
    "            # Extract relevant fields\n",
    "            team_id = player_stats['teamId']\n",
    "            team_name = player_stats['teamCity'] + \" \" + player_stats['teamName']\n",
    "            player_id = player_stats['personId']\n",
    "            player_name = player_stats['firstName'] + \" \" + player_stats['familyName']\n",
    "            position = player_stats['position']\n",
    "            comment = player_stats['comment']\n",
    "            offensive_rating = player_stats['offensiveRating']\n",
    "            defensive_rating = player_stats['defensiveRating']\n",
    "            net_rating = player_stats['netRating']\n",
    "            assist_percentage = player_stats['assistPercentage']\n",
    "            assist_turnover_ratio = player_stats['assistToTurnover']\n",
    "            assist_ratio = player_stats['assistRatio']\n",
    "            usage = player_stats['usagePercentage']\n",
    "            possessions = player_stats['possessions']\n",
    "            eff_fg = player_stats['effectiveFieldGoalPercentage']\n",
    "            true_shooting = player_stats['trueShootingPercentage']\n",
    "            impact_score = player_stats['PIE']\n",
    "\n",
    "            # Create a DataFrame for the current player\n",
    "            df_row = pd.DataFrame({\n",
    "                'game_id': game_id,\n",
    "                'team_id': team_id,\n",
    "                'team_name': team_name,\n",
    "                'player_id': player_id,\n",
    "                'player_name': player_name,\n",
    "                'position': position,\n",
    "                'comment': comment,\n",
    "                'offensive_rating': offensive_rating,\n",
    "                'defensive_rating': defensive_rating,\n",
    "                'net_rating': net_rating,\n",
    "                'assist_percentage': assist_percentage,\n",
    "                'assist_turnover_ratio': assist_turnover_ratio,\n",
    "                'assist_ratio': assist_ratio,\n",
    "                'usage_percentage': usage,\n",
    "                'possessions': possessions,\n",
    "                'effective_fg_percentage': eff_fg,\n",
    "                'true_shooting_percentage': true_shooting,\n",
    "                'player_impact_score': impact_score\n",
    "            }, index=[0])\n",
    "\n",
    "            # Append the DataFrame row to the list\n",
    "            df_row.to_csv('player_advanced_stats.csv', mode='a', index=False, header=False)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        # Sleep to avoid hitting the rate limit\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# manually add csv headers and then convert csv to parquet\n",
    "# df = pd.read_csv('player_advanced_stats.csv')\n",
    "# df.to_parquet('Static Files/current_player_advanced_game_stats.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Advanced Team Game Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'current_team_advanced_game_stats.parquet' not in os.listdir('Static Files'):\n",
    "\n",
    "    # Filter games for the 2023-24 season\n",
    "    games = game_log_df[game_log_df['SEASON_YEAR'] == '2023-24']['GAME_ID'].unique()\n",
    "\n",
    "    # Iterate over each game\n",
    "    for game_id in tqdm(games):\n",
    "        # Fetch box score data for the current game\n",
    "        game = boxscoreadvancedv3.BoxScoreAdvancedV3(game_id).get_data_frames()[1]\n",
    "\n",
    "        # Iterate over each player in the game\n",
    "        for idx, player_stats in game.iterrows():\n",
    "            # Extract relevant fields\n",
    "            team_id = player_stats['teamId']\n",
    "            team_name = player_stats['teamCity'] + \" \" + player_stats['teamName']\n",
    "            offensive_rating = player_stats['offensiveRating']\n",
    "            defensive_rating = player_stats['defensiveRating']\n",
    "            net_rating = player_stats['netRating']\n",
    "            assist_percentage = player_stats['assistPercentage']\n",
    "            assist_turnover_ratio = player_stats['assistToTurnover']\n",
    "            assist_ratio = player_stats['assistRatio']\n",
    "            possessions = player_stats['possessions']\n",
    "            eff_fg = player_stats['effectiveFieldGoalPercentage']\n",
    "            true_shooting = player_stats['trueShootingPercentage']\n",
    "\n",
    "            # Create a DataFrame for the current player\n",
    "            df_row = pd.DataFrame({\n",
    "                'game_id': game_id,\n",
    "                'team_id': team_id,\n",
    "                'team_name': team_name,\n",
    "                'offensive_rating': offensive_rating,\n",
    "                'defensive_rating': defensive_rating,\n",
    "                'net_rating': net_rating,\n",
    "                'assist_percentage': assist_percentage,\n",
    "                'assist_turnover_ratio': assist_turnover_ratio,\n",
    "                'assist_ratio': assist_ratio,\n",
    "                'possessions': possessions,\n",
    "                'effective_fg_percentage': eff_fg,\n",
    "                'true_shooting_percentage': true_shooting,\n",
    "            }, index=[0])\n",
    "\n",
    "            # Append the DataFrame row to the list\n",
    "            df_row.to_csv('team_advanced_stats.csv', mode='a', index=False, header=False)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        # Sleep to avoid hitting the rate limit\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# manually add csv headers and then convert csv to parquet\n",
    "# df = pd.read_csv('team_advanced_stats.csv')\n",
    "# df.to_parquet('Static Files/current_team_advanced_game_stats.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out ML capabilities\n",
    "### In this section, I will create two base models:\n",
    "#### - One to predict the game winner\n",
    "#### - One to predict the MVP for the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get base dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('Static Files/current_player_advanced_game_stats.parquet')\n",
    "df_columns = ['game_id', 'team_id', 'player_id']\n",
    "game_log_columns = ['GAME_ID', 'TEAM_ID', 'PLAYER_ID']\n",
    "game_log_columns2 = ['GAME_ID', 'TEAM_ID']\n",
    "for column in df_columns:\n",
    "    df[column] = df[column].astype(str)\n",
    "for column in game_log_columns:\n",
    "    game_log_df[column] = game_log_df[column].astype(str)\n",
    "for column in game_log_columns2:\n",
    "    game_log_df2[column] = game_log_df2[column].astype(str)\n",
    "\n",
    "game_log_df['GAME_ID'] = game_log_df['GAME_ID'].str[2:]\n",
    "game_log_df2['GAME_ID'] = game_log_df2['GAME_ID'].str[2:]\n",
    "\n",
    "player_game_stats = df.merge(game_log_df, left_on=['game_id', 'team_id', 'player_id'], right_on=['GAME_ID', 'TEAM_ID', 'PLAYER_ID'], how='left')\n",
    "player_game_stats = player_game_stats.merge(game_log_df2, left_on=['game_id', 'team_id'], right_on=['GAME_ID', 'TEAM_ID'], how='left', suffixes=('_player', '_team'))\n",
    "\n",
    "# column operations\n",
    "player_game_stats = player_game_stats[player_game_stats.columns.drop(list(player_game_stats.filter(regex='_RANK_team')))]\n",
    "player_game_stats = player_game_stats[player_game_stats.columns.drop(list(player_game_stats.filter(regex='_RANK_player')))]\n",
    "player_game_stats.columns = [x.lower() for x in player_game_stats.columns]\n",
    "\n",
    "player_game_stats['is_home'] = np.where(player_game_stats['matchup_player'].str.contains('vs.'), 1, 0)\n",
    "player_game_stats = player_game_stats.loc[:, ~player_game_stats.columns.duplicated()]\n",
    "player_game_stats.dropna(subset=['pts_player'], inplace=True)\n",
    "player_game_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_advanced_columns = ['game_id', 'team_id']\n",
    "\n",
    "\n",
    "team_advanced_stats = pd.read_parquet('Static Files/current_team_advanced_game_stats.parquet')\n",
    "\n",
    "for column in team_advanced_columns:\n",
    "    team_advanced_stats[column] = team_advanced_stats[column].astype(str)\n",
    "team_advanced_stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep data for first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all unnecessary columns\n",
    "game_winner_train = player_game_stats[['game_id', 'team_id', 'is_home', 'fgm_team', 'fga_team', 'fg_pct_team', 'fg3m_team', 'fg3a_team', 'fg3_pct_team', 'ftm_team', 'fta_team', 'ft_pct_team', 'oreb_team', 'dreb_team', 'reb_team', 'ast_team', 'tov_team', 'stl_team', 'blk_team', 'pf_team', 'pfd_team', 'pts_team', 'wl_team']]\n",
    "game_winner_train = game_winner_train.merge(team_advanced_stats, on=['game_id', 'team_id'])\n",
    "game_winner_train.drop_duplicates(subset=['game_id', 'team_id'], inplace=True)\n",
    "games = []\n",
    "for game in game_winner_train['game_id'].unique():\n",
    "    games.append(\"00\"+game)\n",
    "game_winner_train.drop(columns=['game_id', 'team_id', 'team_name'], inplace=True)\n",
    "\n",
    "# rename columns\n",
    "game_winner_train.columns = game_winner_train.columns.str.replace('_team', '', regex=False)\n",
    "\n",
    "# convert boolean labels to boolean types\n",
    "game_winner_train['wl'] = game_winner_train['wl'].str.replace('L','0').replace('W','1')\n",
    "game_winner_train['wl'] = np.where(game_winner_train['wl'] == '0', 0, 1)\n",
    "\n",
    "game_winner_train.reset_index().drop(columns='index', inplace=True)\n",
    "game_winner_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Training Data to First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "X = game_winner_train.drop(columns=['wl'])\n",
    "y = game_winner_train['wl']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_winner_train['prediction'] = model.predict(X)\n",
    "game_winner_train['outcome'] = np.where(game_winner_train['wl'] == game_winner_train['prediction'], True, False)\n",
    "print(f'Accuracy: {round(model.score(X, y)*100, 2)}%')\n",
    "game_winner_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def camel_to_snake(name):\n",
    "    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n",
    "\n",
    "# Convert all column headers in the DataFrame\n",
    "player_game_stats.columns = [camel_to_snake(col) for col in player_stats_df.columns]\n",
    "player_stats_df.groupby(['player_id'])[list(player_stats_df.columns[19:])].max().reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
