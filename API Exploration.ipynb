{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import teamdetails, commonteamyears, teamgamelogs, playergamelogs, commonplayerinfo, boxscoreadvancedv3, boxscoretraditionalv3, boxscoremiscv3, scoreboardv2\n",
    "from nba_api.live.nba.endpoints import playbyplay\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandavro as pdx\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "from warnings import filterwarnings\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Team IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'all_teams.parquet' not in os.listdir('Static Files'):\n",
    "    teams = commonteamyears.CommonTeamYears()\n",
    "    print('Established connection')\n",
    "    teams = teams.get_dict()\n",
    "    print('Retrieved list of dicts')\n",
    "    team_ids = []\n",
    "    for team in tqdm(teams['resultSets'][0]['rowSet']):\n",
    "        team_id = team[1]\n",
    "        team_name = team[2]\n",
    "        start_year = team[3]\n",
    "        end_year = team[4]\n",
    "        team_ids.append((team_id, team_name, start_year, end_year))\n",
    "        time.sleep(0.5)\n",
    "    print('Established list of tuples')\n",
    "    teams = pd.DataFrame(team_ids, columns=['team_id', 'year_founded', 'year_depreciated', 'abbreviation'])\n",
    "    print('Created DataFrame')\n",
    "    teams.to_parquet('Static Files/all_teams.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Team Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'team_details.parquet' not in os.listdir('Static Files'):\n",
    "    teams = pd.read_parquet('Static Files/all_teams.parquet')\n",
    "    initial_df = []\n",
    "    for team in tqdm(teams['team_id']):\n",
    "        get_coaches = teamdetails.TeamDetails(team_id=team, timeout=60)\n",
    "        next_df = get_coaches.get_data_frames()[0]\n",
    "        initial_df.append(next_df)\n",
    "        time.sleep(0.5)\n",
    "    output_df = pd.concat(initial_df)\n",
    "    output_df.to_parquet('Static Files/team_details.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Team Game Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'team_game_logs.parquet' not in os.listdir('Static Files'):\n",
    "    start = 0\n",
    "    end = 1\n",
    "    initial_df = []\n",
    "    for integer in tqdm(range(1,25)):\n",
    "        if end < 10:\n",
    "            get_game_stats = teamgamelogs.TeamGameLogs(season_nullable=f'200{start}-0{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "            start += 1\n",
    "            end += 1\n",
    "        else:\n",
    "            start += 1\n",
    "            end += 1\n",
    "            get_game_stats = teamgamelogs.TeamGameLogs(season_nullable=f'20{start}-{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    output_df = pd.concat(initial_df)\n",
    "    output_df.to_parquet('Static Files/team_game_logs.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Current Player Injury Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'player_injury_reports.avro' not in os.listdir('Static Files'):\n",
    "    player_injuries = pd.concat(pd.read_html('https://www.espn.com/nba/injuries')).fillna('No Info Available')\n",
    "    player_injuries['date_updated'] = datetime.today()\n",
    "    pdx.to_avro('Static Files/player_injury_reports.avro', player_injuries)\n",
    "elif ('player_injury_reports.avro' in os.listdir('Static Files')):\n",
    "    player_injuries = pdx.read_avro('Static Files/player_injury_reports.avro')\n",
    "    if player_injuries['date_updated'].all() != datetime.today():\n",
    "        player_injuries = pd.concat(pd.read_html('https://www.espn.com/nba/injuries')).fillna('No Info Available')\n",
    "        player_injuries['date_updated'] = datetime.today()\n",
    "        pdx.to_avro('Static Files/player_injury_reports.avro', player_injuries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Player Game Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'player_game_logs.parquet' not in os.listdir('Static Files'):\n",
    "    start = 0\n",
    "    end = 1\n",
    "    initial_df = []\n",
    "    for integer in tqdm(range(1,25)):\n",
    "        if end < 10:\n",
    "            get_game_stats = playergamelogs.PlayerGameLogs(season_nullable=f'200{start}-0{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "            start += 1\n",
    "            end += 1\n",
    "        else:\n",
    "            start += 1\n",
    "            end += 1\n",
    "            get_game_stats = playergamelogs.PlayerGameLogs(season_nullable=f'20{start}-{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    output_df = pd.concat(initial_df)\n",
    "    output_df.to_parquet('Static Files/player_game_logs.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Games Next Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '2024-25_game_ids.parquet' not in os.listdir('Static Files'):\n",
    "    start = datetime.strptime(\"2024-10-04\", \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(\"2025-04-15\", \"%Y-%m-%d\")\n",
    "\n",
    "    date_range = pd.date_range(start=start, end=end).to_list()\n",
    "\n",
    "    games = {}\n",
    "    # Assuming 'range' contains the list of dates for the 2024-25 season\n",
    "    for date in tqdm(date_range):\n",
    "        json_string = json.loads(scoreboardv2.ScoreboardV2(game_date=date).get_json())\n",
    "\n",
    "        i = 0  # resultSets index for 'GameHeader'\n",
    "        headers = json_string['resultSets'][i].get('headers', '')\n",
    "\n",
    "        # Iterate through each game in the 'rowSet'\n",
    "        for game in json_string['resultSets'][i]['rowSet']:\n",
    "            game_id = game[2]  # Index 2 is the 'GAME_ID'\n",
    "\n",
    "            # Add game_id to the list of games for the specific date\n",
    "            if date in games:\n",
    "                games[date].append(game_id)\n",
    "            else:\n",
    "                games[date] = [game_id]\n",
    "\n",
    "        time.sleep(0.5)  # Delay to avoid rate limits\n",
    "    games = {key.strftime('%Y-%m-%d'): value for key, value in games.items()}\n",
    "    games_2025 = pd.DataFrame(list(games.items()), columns=['game_date', 'game_id'])\n",
    "    games_2025 = games_2025.explode(column='game_id')\n",
    "    games_2025.to_parquet('Static Files/2024-25_game_ids.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Play by Play Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting mock live updates for game: 0022000196\n"
     ]
    }
   ],
   "source": [
    "game_log_df = pd.read_parquet('Static Files/current_player_game_logs.parquet')\n",
    "game_log_df2 = pd.read_parquet('Static Files/team_game_logs.parquet')\n",
    "\n",
    "def simulation(game_id):\n",
    "    print(f\"Starting mock live updates for game: {game_id}\")\n",
    "    play_by_play = playbyplay.PlayByPlay(game_id)\n",
    "    plays = play_by_play.get_dict()['game']['actions']\n",
    "    plays_df = []\n",
    "    for _ in range(len(plays)):\n",
    "        if plays:\n",
    "            latest_play = plays[_]\n",
    "            try:\n",
    "                period = latest_play['period']\n",
    "                period_time_remaining = latest_play['clock'].replace('PT', '').replace('M', ':')[:5]\n",
    "                description = latest_play['description']\n",
    "                home_score = latest_play['scoreHome']\n",
    "                away_score = latest_play['scoreAway']\n",
    "                df2 = pd.DataFrame({'game_id':game_id, 'period':period, 'period_time_remaining':period_time_remaining, 'description':description, 'home_score':home_score, 'away_score':away_score}, index=[0])\n",
    "                plays_df.append(df2)\n",
    "                # print(f\"Q{period} {game_clock}: {description} | Score: {home_score} - {away_score}\")\n",
    "            except KeyError:\n",
    "                pass\n",
    "        else:\n",
    "            print(\"no plays yet...\")\n",
    "    output = pd.concat(plays_df, ignore_index=True)\n",
    "    return output\n",
    "current_game = simulation('0022000196')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Advanced Player Game Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'current_player_advanced_game_stats.parquet' not in os.listdir('Static Files'):\n",
    "    # Filter games for the 2023-24 season\n",
    "    games = game_log_df[game_log_df['SEASON_YEAR'] == '2023-24']['GAME_ID'].unique()\n",
    "    rows = []\n",
    "\n",
    "    # Iterate over each game\n",
    "    for game_id in tqdm(games):\n",
    "        try:\n",
    "            # Fetch box score data for the current game\n",
    "            game = boxscoreadvancedv3.BoxScoreAdvancedV3(game_id).get_data_frames()[0]\n",
    "\n",
    "            # Extract relevant fields and append rows\n",
    "            rows.extend([{\n",
    "                'game_id': game_id,\n",
    "                'team_id': player_stats.teamId,\n",
    "                'team_name': f\"{player_stats.teamCity} {player_stats.teamName}\",\n",
    "                'player_id': player_stats.personId,\n",
    "                'player_name': f\"{player_stats.firstName} {player_stats.familyName}\",\n",
    "                'position': player_stats.position,\n",
    "                'comment': player_stats.comment,\n",
    "                'offensive_rating': player_stats.offensiveRating,\n",
    "                'defensive_rating': player_stats.defensiveRating,\n",
    "                'net_rating': player_stats.netRating,\n",
    "                'assist_percentage': player_stats.assistPercentage,\n",
    "                'assist_turnover_ratio': player_stats.assistToTurnover,\n",
    "                'assist_ratio': player_stats.assistRatio,\n",
    "                'usage_percentage': player_stats.usagePercentage,\n",
    "                'possessions': player_stats.possessions,\n",
    "                'effective_fg_percentage': player_stats.effectiveFieldGoalPercentage,\n",
    "                'true_shooting_percentage': player_stats.trueShootingPercentage,\n",
    "                'player_impact_score': player_stats.PIE\n",
    "            } for player_stats in game.itertuples()])\n",
    "\n",
    "            # Sleep to avoid hitting the rate limit\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing game {game_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Convert list of rows to DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Save to Parquet\n",
    "    df.to_parquet('Static Files/current_player_advanced_game_stats.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Advanced Team Game Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_team_advanced_stats():\n",
    "\n",
    "    if 'current_team_advanced_game_stats.parquet' not in os.listdir('Static Files'):\n",
    "        # Filter games for the 2023-24 season\n",
    "        games = game_log_df2[game_log_df2['SEASON_YEAR'] == '2023-24']['GAME_ID'].unique()\n",
    "        rows = []\n",
    "\n",
    "        # Iterate over each game\n",
    "        for game_id in tqdm(games):\n",
    "            try:\n",
    "                # Fetch box score data for the current game\n",
    "                game = boxscoreadvancedv3.BoxScoreAdvancedV3(game_id).get_data_frames()[1]\n",
    "\n",
    "                # Extract relevant fields and append rows\n",
    "                rows.extend([{\n",
    "                    'game_id': game_id,\n",
    "                    'team_id': team_stats.teamId,\n",
    "                    'team_name': f\"{team_stats.teamCity} {team_stats.teamName}\",\n",
    "                    'offensive_rating': team_stats.offensiveRating,\n",
    "                    'defensive_rating': team_stats.defensiveRating,\n",
    "                    'net_rating': team_stats.netRating,\n",
    "                    'assist_percentage': team_stats.assistPercentage,\n",
    "                    'assist_turnover_ratio': team_stats.assistToTurnover,\n",
    "                    'assist_ratio': team_stats.assistRatio,\n",
    "                    'possessions': team_stats.possessions,\n",
    "                    'effective_fg_percentage': team_stats.effectiveFieldGoalPercentage,\n",
    "                    'true_shooting_percentage': team_stats.trueShootingPercentage\n",
    "                } for team_stats in game.itertuples()])\n",
    "\n",
    "                # Sleep to avoid hitting the rate limit\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                print(f\"last processed game: {game_id}\")\n",
    "                df = pd.DataFrame(rows)\n",
    "                df.to_parquet('Static Files/current_team_advanced_game_stats.parquet')\n",
    "\n",
    "        # Convert list of rows to DataFrame\n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "        # Save to Parquet\n",
    "        df.to_parquet('Static Files/current_team_advanced_game_stats.parquet')\n",
    "\n",
    "# Run the function\n",
    "fetch_team_advanced_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_date  game_date\n",
       "2024       10           25\n",
       "           11           28\n",
       "           12           25\n",
       "2025       1            31\n",
       "           2            23\n",
       "           3            31\n",
       "           4            12\n",
       "Name: game_date, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_games = pd.read_parquet('Static Files/2024-25_game_ids.parquet')\n",
    "next_games['game_date'] = pd.to_datetime(next_games['game_date'])\n",
    "next_games['game_date'].groupby([next_games.game_date.dt.year, next_games.game_date.dt.month]).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1230/1230 [18:31<00:00,  1.11it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     game_plays\u001b[38;5;241m.\u001b[39mupdate({game:\u001b[38;5;28mlen\u001b[39m(json\u001b[38;5;241m.\u001b[39mloads(plays)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m])})\n\u001b[0;32m      6\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame_plays\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\10881132\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\10881132\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\10881132\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\10881132\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:667\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "games = pd.read_parquet('Static Files/team_game_logs.parquet').query('SEASON_YEAR == \"2023-24\"')['GAME_ID'].unique()\n",
    "game_plays = {}\n",
    "for game in tqdm(list(games)):\n",
    "    plays = playbyplay.PlayByPlay(game).get_json()\n",
    "    game_plays.update({game:len(json.loads(plays)['game']['actions'])})\n",
    "    time.sleep(0.5)\n",
    "pd.DataFrame(game_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>548.729268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>37.315239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>524.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>546.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>570.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>714.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1230.000000\n",
       "mean    548.729268\n",
       "std      37.315239\n",
       "min     442.000000\n",
       "25%     524.000000\n",
       "50%     546.000000\n",
       "75%     570.750000\n",
       "max     714.000000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(game_plays, orient='index').reset_index().describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
