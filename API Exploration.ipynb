{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import teamdetails, commonteamyears, teamgamelogs, playergamelogs, commonplayerinfo, boxscoreadvancedv3, boxscoretraditionalv3, boxscoremiscv3, scoreboardv2\n",
    "from nba_api.live.nba.endpoints import playbyplay\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandavro as pdx\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "from warnings import filterwarnings\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Team IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'all_teams.parquet' not in os.listdir('Static Files'):\n",
    "    teams = commonteamyears.CommonTeamYears()\n",
    "    print('Established connection')\n",
    "    teams = teams.get_dict()\n",
    "    print('Retrieved list of dicts')\n",
    "    team_ids = []\n",
    "    for team in tqdm(teams['resultSets'][0]['rowSet']):\n",
    "        team_id = team[1]\n",
    "        team_name = team[2]\n",
    "        start_year = team[3]\n",
    "        end_year = team[4]\n",
    "        team_ids.append((team_id, team_name, start_year, end_year))\n",
    "        time.sleep(0.5)\n",
    "    print('Established list of tuples')\n",
    "    teams = pd.DataFrame(team_ids, columns=['team_id', 'year_founded', 'year_depreciated', 'abbreviation'])\n",
    "    print('Created DataFrame')\n",
    "    teams.to_parquet('Static Files/all_teams.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Team Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'team_details.parquet' not in os.listdir('Static Files'):\n",
    "    teams = pd.read_parquet('Static Files/all_teams.parquet')\n",
    "    initial_df = []\n",
    "    for team in tqdm(teams['team_id']):\n",
    "        get_coaches = teamdetails.TeamDetails(team_id=team, timeout=60)\n",
    "        next_df = get_coaches.get_data_frames()[0]\n",
    "        initial_df.append(next_df)\n",
    "        time.sleep(0.5)\n",
    "    output_df = pd.concat(initial_df)\n",
    "    output_df.to_parquet('Static Files/team_details.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Team Game Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'team_game_logs.parquet' not in os.listdir('Static Files'):\n",
    "    start = 0\n",
    "    end = 1\n",
    "    initial_df = []\n",
    "    for integer in tqdm(range(1,25)):\n",
    "        if end < 10:\n",
    "            get_game_stats = teamgamelogs.TeamGameLogs(season_nullable=f'200{start}-0{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "            start += 1\n",
    "            end += 1\n",
    "        else:\n",
    "            start += 1\n",
    "            end += 1\n",
    "            get_game_stats = teamgamelogs.TeamGameLogs(season_nullable=f'20{start}-{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    output_df = pd.concat(initial_df)\n",
    "    output_df.to_parquet('Static Files/team_game_logs.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Current Player Injury Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'player_injury_reports.avro' not in os.listdir('Static Files'):\n",
    "    player_injuries = pd.concat(pd.read_html('https://www.espn.com/nba/injuries')).fillna('No Info Available')\n",
    "    player_injuries['date_updated'] = datetime.today()\n",
    "    pdx.to_avro('Static Files/player_injury_reports.avro', player_injuries)\n",
    "elif ('player_injury_reports.avro' in os.listdir('Static Files')):\n",
    "    player_injuries = pdx.read_avro('Static Files/player_injury_reports.avro')\n",
    "    if player_injuries['date_updated'].all() != datetime.today():\n",
    "        player_injuries = pd.concat(pd.read_html('https://www.espn.com/nba/injuries')).fillna('No Info Available')\n",
    "        player_injuries['date_updated'] = datetime.today()\n",
    "        pdx.to_avro('Static Files/player_injury_reports.avro', player_injuries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Player Game Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'player_game_logs.parquet' not in os.listdir('Static Files'):\n",
    "    start = 0\n",
    "    end = 1\n",
    "    initial_df = []\n",
    "    for integer in tqdm(range(1,25)):\n",
    "        if end < 10:\n",
    "            get_game_stats = playergamelogs.PlayerGameLogs(season_nullable=f'200{start}-0{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "            start += 1\n",
    "            end += 1\n",
    "        else:\n",
    "            start += 1\n",
    "            end += 1\n",
    "            get_game_stats = playergamelogs.PlayerGameLogs(season_nullable=f'20{start}-{end}')\n",
    "            next_df = get_game_stats.get_data_frames()[0]\n",
    "            initial_df.append(next_df)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    output_df = pd.concat(initial_df)\n",
    "    output_df.to_parquet('Static Files/player_game_logs.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Player Statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    players = pd.read_parquet('Static Files/player_game_logs.parquet')[['PLAYER_ID']].drop_duplicates()\n",
    "    statuses = pdx.read_avro('Static Files/player_statuses.avro')\n",
    "    df3 = players.merge(statuses, left_on='PLAYER_ID', right_on='PERSON_ID', how='left', indicator=True)\n",
    "    df = df3.loc[df3['_merge'] == 'left_only', 'PLAYER_ID']\n",
    "    d = players[players['PLAYER_ID'].isin(df)]\n",
    "    d = statuses.merge(d, left_on='PERSON_ID', right_on='PLAYER_ID', how='right')\n",
    "except:\n",
    "    pass\n",
    "if 'player_statuses.avro' not in os.listdir('Static Files'):\n",
    "    players = pd.read_parquet('Static Files/player_game_logs.parquet')[['PLAYER_ID']].drop_duplicates()\n",
    "    for player in tqdm(players['PLAYER_ID']):\n",
    "        player_status = commonplayerinfo.CommonPlayerInfo(player_id=player).get_data_frames()[0][['PERSON_ID', 'ROSTERSTATUS']]\n",
    "        pdx.to_avro('Static Files/player_statuses.avro', player_status, append=True)\n",
    "        statuses = pdx.read_avro('Static Files/player_statuses.avro')\n",
    "        players = pd.read_parquet('Static Files/player_game_logs.parquet')[['PLAYER_ID']].drop_duplicates()\n",
    "        # carrying out anti join using merge method\n",
    "        df3 = players.merge(statuses, left_on='PLAYER_ID', right_on='PERSON_ID', how='left', indicator=True)\n",
    "        df = df3.loc[df3['_merge'] == 'left_only', 'PLAYER_ID']\n",
    "        d = players[players['PLAYER_ID'].isin(df)]\n",
    "        d = statuses.merge(d, left_on='PERSON_ID', right_on='PLAYER_ID', how='right')\n",
    "        time.sleep(0.5)\n",
    "elif ('player_statuses.avro' in os.listdir('Static Files')) & len(d[['PLAYER_ID']].drop_duplicates()['PLAYER_ID']) > 0:\n",
    "    statuses = pdx.read_avro('Static Files/player_statuses.avro')\n",
    "    players = pd.read_parquet('Static Files/player_game_logs.parquet')[['PLAYER_ID']].drop_duplicates()\n",
    "    # carrying out anti join using merge method\n",
    "    df3 = players.merge(statuses, left_on='PLAYER_ID', right_on='PERSON_ID', how='left', indicator=True)\n",
    "    df = df3.loc[df3['_merge'] == 'left_only', 'PLAYER_ID']\n",
    "    d = players[players['PLAYER_ID'].isin(df)]\n",
    "    d = statuses.merge(d, left_on='PERSON_ID', right_on='PLAYER_ID', how='right')\n",
    "    for player in tqdm(d[['PLAYER_ID']].drop_duplicates()['PLAYER_ID']):\n",
    "        player_status = commonplayerinfo.CommonPlayerInfo(player_id=player).get_data_frames()[0][['PERSON_ID', 'ROSTERSTATUS']]\n",
    "        pdx.to_avro('Static Files/player_statuses.avro', player_status, append=True)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Current Player Game Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'current_player_game_logs.parquet' not in os.listdir('Static Files'):\n",
    "    player_game_logs = pd.read_parquet('Static Files/player_game_logs.parquet')\n",
    "    current_player_game_logs = player_game_logs.merge(statuses, left_on='PLAYER_ID', right_on='PERSON_ID').query('ROSTERSTATUS == \"Active\"').to_parquet('Static Files/current_player_game_logs.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Out Live Play-By-Play End Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'play_by_play_example.parquet' not in os.listdir('Static Files'):\n",
    "    # Game ID for the live game you are tracking (replace with actual game ID)\n",
    "    game_id = \"0022301196\"\n",
    "\n",
    "    # DataFrame to store all player stats during the game\n",
    "    player_stats_df = pd.DataFrame()\n",
    "\n",
    "    # Track the last processed play to avoid duplicates\n",
    "    last_processed_play = None\n",
    "    pbp_data = playbyplay.PlayByPlay(game_id).get_dict()\n",
    "    plays = pbp_data['game']['actions']\n",
    "\n",
    "    # Sort plays by actionNumber to process them in order\n",
    "    plays.sort(key=lambda x: x['actionNumber'])\n",
    "\n",
    "    # Print the total number of plays\n",
    "    print(f\"Total number of plays: {len(plays)}\")\n",
    "\n",
    "    for play in tqdm(plays, desc=\"Processing plays\"):\n",
    "        action_number = play['actionNumber']\n",
    "        player_id = play.get('personId', None)\n",
    "        action_type = play.get('actionType', '')\n",
    "        clock = play.get('clock', '')\n",
    "        description = play.get(\"description\", \"\")\n",
    "        descriptor = play.get(\"descriptor\", \"\")\n",
    "        period = play.get(\"period\", \"\")\n",
    "        periodType = play.get(\"periodType\", \"\")\n",
    "        qualifiers = play.get(\"qualifiers\", \"\")\n",
    "        shotDistance = play.get(\"shotDistance\", \"\")\n",
    "        shotResult = play.get(\"shotResult\", \"\")\n",
    "        side = play.get(\"side\", \"\")\n",
    "\n",
    "        # Only process the play if it's new (not processed yet)\n",
    "        if last_processed_play is None or action_number > last_processed_play:\n",
    "\n",
    "            try:\n",
    "                # Fetch traditional stats\n",
    "                traditional_boxscore = boxscoretraditionalv3.BoxScoreTraditionalV3(game_id=game_id)\n",
    "                traditional_stats = traditional_boxscore.get_data_frames()[0]\n",
    "\n",
    "                # Fetch advanced stats\n",
    "                advanced_boxscore = boxscoreadvancedv3.BoxScoreAdvancedV3(game_id=game_id)\n",
    "                advanced_stats = advanced_boxscore.get_data_frames()[0]\n",
    "\n",
    "                # Fetch miscellaneous stats\n",
    "                misc_boxscore = boxscoremiscv3.BoxScoreMiscV3(game_id=game_id)\n",
    "                misc_stats = misc_boxscore.get_data_frames()[0]\n",
    "\n",
    "                # Find the stats for the player involved in the play\n",
    "                traditional_player_stats = traditional_stats[traditional_stats['personId'] == player_id]\n",
    "                advanced_player_stats = advanced_stats[advanced_stats['personId'] == player_id]\n",
    "                misc_player_stats = misc_stats[misc_stats['personId'] == player_id]\n",
    "\n",
    "                if not traditional_player_stats.empty and not advanced_player_stats.empty and not misc_player_stats.empty:\n",
    "                    # Extract all columns from traditional stats\n",
    "                    traditional_columns = traditional_player_stats.columns.tolist()\n",
    "                    traditional_values = traditional_player_stats.iloc[0].tolist()\n",
    "\n",
    "                    # Extract all columns from advanced stats\n",
    "                    advanced_columns = advanced_player_stats.columns.tolist()\n",
    "                    advanced_values = advanced_player_stats.iloc[0].tolist()\n",
    "\n",
    "                    # Extract all columns from miscellaneous stats\n",
    "                    misc_columns = misc_player_stats.columns.tolist()\n",
    "                    misc_values = misc_player_stats.iloc[0].tolist()\n",
    "\n",
    "                    # Combine all stats into one dictionary\n",
    "                    player_data = {\n",
    "                        'player_id': player_id,\n",
    "                        'action_type': action_type,\n",
    "                        'game_id': game_id,\n",
    "                        'clock': clock,\n",
    "                        'description': description,\n",
    "                        'descriptor': descriptor,\n",
    "                        'period': period,\n",
    "                        'period_type': periodType,\n",
    "                        'qualifiers': qualifiers,\n",
    "                        'shot_distance': shotDistance,\n",
    "                        'shot_result': shotResult,\n",
    "                        'side': side\n",
    "                    }\n",
    "\n",
    "                    # Add traditional stats to player_data\n",
    "                    player_data.update(dict(zip(traditional_columns, traditional_values)))\n",
    "\n",
    "                    # Add advanced stats to player_data\n",
    "                    player_data.update(dict(zip(advanced_columns, advanced_values)))\n",
    "\n",
    "                    # Add miscellaneous stats to player_data\n",
    "                    player_data.update(dict(zip(misc_columns, misc_values)))\n",
    "\n",
    "                    # Append the new data to the DataFrame\n",
    "                    player_stats_df = pd.concat([player_stats_df, pd.DataFrame([player_data])], ignore_index=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"Error processing play {action_number}: {e}\")\n",
    "\n",
    "            # Update the last processed play\n",
    "            last_processed_play = action_number\n",
    "\n",
    "            # Sleep before fetching the next batch of plays (adjust this time to API rate limit)\n",
    "            time.sleep(1)\n",
    "    try:\n",
    "        player_stats_df['team_name'] = player_stats_df['teamCity'] + \" \" + player_stats_df['teamName']\n",
    "        player_stats_df.drop(columns=['gameId', 'teamTricode', 'teamSlug', 'personId', 'firstName', 'familyName', 'playerSlug', 'estimatedOffensiveRating', 'estimatedDefensiveRating', 'estimatedNetRating', 'offensiveReboundPercentage', 'defensiveReboundPercentage', 'turnoverRatio', 'estimatedUsagePercentage', 'estimatedPace', 'jerseyNum', 'teamCity', 'teamName'], inplace=True)\n",
    "    except KeyError:\n",
    "        player_stats_df.rename(columns={'teamId':'team_id', 'nameI':'player_name', 'fieldGoalsMade':'fg_made', 'fieldGoalsAttempted':'fg_attempts', 'fieldGoalPercentage':'fg_percentage','threePointersMade':'fg3_made', 'threePointersAttempted':'fg3_attempts', 'threePointersPercentage':'fg3_percentage', 'freeThrowsMade':'ft_made', 'freeThrowsAttempted':'ft_attempts', 'freeThrowPercentage':'ft_percentage', 'reboundsOffensive':'offensive_rebounds', 'reboundsDefensive':'defensive_rebounds', 'reboundsTotal':'total_rebounds', 'foulsPersonal':'personal_fouls', 'plusMinusPoints':'plus_minus', 'offensiveRating':'offensive_rating', 'defensiveRating':'defensive_rating', 'netRating':'net_rating', 'assistPercentage':'assist_percentage', 'assistToTurnover':'assist_turnover_ratio', 'assistRatio':'assist_ratio', 'reboundPercentage':'rebound_percentage', 'effectiveFieldGoalPercentage':'eff_fg_percentage', 'trueShootingPercentage':'true_shooting_percentage', 'usagePercentage':'usage_percentage', 'pointsOffTurnovers':'turnover_points', 'pointsSecondChance':'second_chance_points', 'pointsFastBreak':'fast_break_points', 'pointsPaint':'paint_points', 'blocksAgainst':'blocks_against', 'foulsDrawn':'fouls_drawn'}, inplace=True)\n",
    "\n",
    "        player_stats_df['clock'] = player_stats_df['clock'].replace('PT', '').replace('M', '').replace('.00S', '')\n",
    "        pd.set_option(\"display.max_columns\", 0)\n",
    "        best_players = player_stats_df.groupby('team_name')['PIE'].idxmax()\n",
    "        best_players = player_stats_df.loc[best_players, ['player_name', 'team_name', 'PIE']]\n",
    "        team_1 = best_players['team_name'].iloc[0]\n",
    "        player_1 = best_players['player_name'].iloc[0]\n",
    "        player_1_pie = best_players['PIE'].iloc[0]\n",
    "        team_2 = best_players['team_name'].iloc[1]\n",
    "        player_2 = best_players['player_name'].iloc[1]\n",
    "        player_2_pie = best_players['PIE'].iloc[1]\n",
    "        display(player_stats_df.head())\n",
    "        print(f'{team_1}: {player_1} ({player_1_pie}) | {team_2}: {player_2} ({player_2_pie})')\n",
    "        player_stats_df.replace(value=np.nan, to_replace='').to_parquet('Static Files/play_by_play_example.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '2024-25_game_ids.parquet' not in os.listdir('Static Files'):\n",
    "    start = datetime.strptime(\"2024-10-04\", \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(\"2025-04-15\", \"%Y-%m-%d\")\n",
    "\n",
    "    date_range = pd.date_range(start=start, end=end).to_list()\n",
    "\n",
    "    games = {}\n",
    "    # Assuming 'range' contains the list of dates for the 2024-25 season\n",
    "    for date in tqdm(date_range):\n",
    "        json_string = json.loads(scoreboardv2.ScoreboardV2(game_date=date).get_json())\n",
    "\n",
    "        i = 0  # resultSets index for 'GameHeader'\n",
    "        headers = json_string['resultSets'][i].get('headers', '')\n",
    "\n",
    "        # Iterate through each game in the 'rowSet'\n",
    "        for game in json_string['resultSets'][i]['rowSet']:\n",
    "            game_id = game[2]  # Index 2 is the 'GAME_ID'\n",
    "\n",
    "            # Add game_id to the list of games for the specific date\n",
    "            if date in games:\n",
    "                games[date].append(game_id)\n",
    "            else:\n",
    "                games[date] = [game_id]\n",
    "\n",
    "        time.sleep(0.5)  # Delay to avoid rate limits\n",
    "    games = {key.strftime('%Y-%m-%d'): value for key, value in games.items()}\n",
    "    games_2025 = pd.DataFrame(list(games.items()), columns=['game_date', 'game_id'])\n",
    "    games_2025 = games_2025.explode(column='game_id')\n",
    "    games_2025.to_parquet('Static Files/2024-25_game_ids.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting mock live updates for game: 0022000196\n"
     ]
    }
   ],
   "source": [
    "game_log_df = pd.read_parquet('Static Files/current_player_game_logs.parquet')\n",
    "game_log_df2 = pd.read_parquet('Static Files/team_game_logs.parquet')\n",
    "\n",
    "def simulation(game_id):\n",
    "    print(f\"Starting mock live updates for game: {game_id}\")\n",
    "    play_by_play = playbyplay.PlayByPlay(game_id)\n",
    "    plays = play_by_play.get_dict()['game']['actions']\n",
    "    df = pd.DataFrame(columns=['game_id','period','period_time_remaining','description','home_score','away_score'])\n",
    "    plays_df = []\n",
    "    for _ in range(len(plays)):\n",
    "        if plays:\n",
    "            latest_play = plays[_]\n",
    "            try:\n",
    "                period = latest_play['period']\n",
    "                period_time_remaining = latest_play['clock'].replace('PT', '').replace('M', ':')[:5]\n",
    "                description = latest_play['description']\n",
    "                home_score = latest_play['scoreHome']\n",
    "                away_score = latest_play['scoreAway']\n",
    "                df2 = pd.DataFrame({'game_id':game_id, 'period':period, 'period_time_remaining':period_time_remaining, 'description':description, 'home_score':home_score, 'away_score':away_score}, index=[0])\n",
    "                plays_df.append(df2)\n",
    "                # print(f\"Q{period} {game_clock}: {description} | Score: {home_score} - {away_score}\")\n",
    "            except KeyError:\n",
    "                pass\n",
    "        else:\n",
    "            print(\"no plays yet...\")\n",
    "    output = pd.concat(plays_df, ignore_index=True)\n",
    "    return output\n",
    "current_game = simulation('0022000196')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Advanced Player Game Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_advanced_stats():\n",
    "\n",
    "    if 'current_player_advanced_game_stats.parquet' not in os.listdir('Static Files'):\n",
    "        # Filter games for the 2023-24 season\n",
    "        games = game_log_df[game_log_df['SEASON_YEAR'] == '2023-24']['GAME_ID'].unique()\n",
    "        rows = []\n",
    "\n",
    "        # Iterate over each game\n",
    "        for game_id in tqdm(games):\n",
    "            try:\n",
    "                # Fetch box score data for the current game\n",
    "                game = boxscoreadvancedv3.BoxScoreAdvancedV3(game_id).get_data_frames()[0]\n",
    "\n",
    "                # Extract relevant fields and append rows\n",
    "                rows.extend([{\n",
    "                    'game_id': game_id,\n",
    "                    'team_id': player_stats.teamId,\n",
    "                    'team_name': f\"{player_stats.teamCity} {player_stats.teamName}\",\n",
    "                    'player_id': player_stats.personId,\n",
    "                    'player_name': f\"{player_stats.firstName} {player_stats.familyName}\",\n",
    "                    'position': player_stats.position,\n",
    "                    'comment': player_stats.comment,\n",
    "                    'offensive_rating': player_stats.offensiveRating,\n",
    "                    'defensive_rating': player_stats.defensiveRating,\n",
    "                    'net_rating': player_stats.netRating,\n",
    "                    'assist_percentage': player_stats.assistPercentage,\n",
    "                    'assist_turnover_ratio': player_stats.assistToTurnover,\n",
    "                    'assist_ratio': player_stats.assistRatio,\n",
    "                    'usage_percentage': player_stats.usagePercentage,\n",
    "                    'possessions': player_stats.possessions,\n",
    "                    'effective_fg_percentage': player_stats.effectiveFieldGoalPercentage,\n",
    "                    'true_shooting_percentage': player_stats.trueShootingPercentage,\n",
    "                    'player_impact_score': player_stats.PIE\n",
    "                } for player_stats in game.itertuples()])\n",
    "\n",
    "                # Sleep to avoid hitting the rate limit\n",
    "                time.sleep(0.5)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing game {game_id}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Convert list of rows to DataFrame\n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "        # Save to Parquet\n",
    "        df.to_parquet('Static Files/current_player_advanced_game_stats.parquet')\n",
    "\n",
    "# Run the function\n",
    "fetch_advanced_stats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Advanced Team Game Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_team_advanced_stats():\n",
    "\n",
    "    if 'current_team_advanced_game_stats.parquet' not in os.listdir('Static Files'):\n",
    "        # Filter games for the 2023-24 season\n",
    "        games = game_log_df2[game_log_df2['SEASON_YEAR'] == '2023-24']['GAME_ID'].unique()\n",
    "        rows = []\n",
    "\n",
    "        # Iterate over each game\n",
    "        for game_id in tqdm(games):\n",
    "            try:\n",
    "                # Fetch box score data for the current game\n",
    "                game = boxscoreadvancedv3.BoxScoreAdvancedV3(game_id).get_data_frames()[1]\n",
    "\n",
    "                # Extract relevant fields and append rows\n",
    "                rows.extend([{\n",
    "                    'game_id': game_id,\n",
    "                    'team_id': team_stats.teamId,\n",
    "                    'team_name': f\"{team_stats.teamCity} {team_stats.teamName}\",\n",
    "                    'offensive_rating': team_stats.offensiveRating,\n",
    "                    'defensive_rating': team_stats.defensiveRating,\n",
    "                    'net_rating': team_stats.netRating,\n",
    "                    'assist_percentage': team_stats.assistPercentage,\n",
    "                    'assist_turnover_ratio': team_stats.assistToTurnover,\n",
    "                    'assist_ratio': team_stats.assistRatio,\n",
    "                    'possessions': team_stats.possessions,\n",
    "                    'effective_fg_percentage': team_stats.effectiveFieldGoalPercentage,\n",
    "                    'true_shooting_percentage': team_stats.trueShootingPercentage\n",
    "                } for team_stats in game.itertuples()])\n",
    "\n",
    "                # Sleep to avoid hitting the rate limit\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                print(f\"last processed game: {game_id}\")\n",
    "                df = pd.DataFrame(rows)\n",
    "                df.to_parquet('Static Files/current_team_advanced_game_stats.parquet')\n",
    "\n",
    "        # Convert list of rows to DataFrame\n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "        # Save to Parquet\n",
    "        df.to_parquet('Static Files/current_team_advanced_game_stats.parquet')\n",
    "\n",
    "# Run the function\n",
    "fetch_team_advanced_stats()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
